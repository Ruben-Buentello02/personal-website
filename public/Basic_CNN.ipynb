{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# üß† Intro to Convolutional Neural Networks (CNNs)\n### üìö A Beginner-Friendly Lesson Using CIFAR-10\n\nWelcome!  \nToday we will learn **how computers understand images** using a type of neural network called a **CNN (Convolutional Neural Network)**.\n\n### üéØ What You Will Learn\n- What a CNN is  \n- Why convolution is useful for images  \n- How to load and visualize the CIFAR-10 dataset  \n- How to build a classifier with TensorFlow/Keras  \n- How to train, evaluate, and visualize predictions  \n- How to modify the model and run your own experiments","metadata":{}},{"cell_type":"markdown","source":"# üñºÔ∏è What Is a Convolutional Neural Network?\n\nA **CNN** is a type of neural network designed for images.\n\n### ü§î How does it work?\nImagine looking at an image. You don't try to understand the whole picture at once ‚Äî  \nyour brain examines **small pieces**, like edges, corners, colors, etc.\n\nCNNs do the same thing:\n\n### üîç Step 1: Filters scan small patches\nA small 3√ó3 matrix (called a **filter**) slides across the image.\n\nIt detects:\n- edges  \n- corners  \n- textures  \n\n### üß± Step 2: Build hierarchical features\n- Early layers detect simple shapes  \n- Later layers detect more complex patterns, like:\n  - eyes  \n  - wheels  \n  - animal shapes  \n\n### üèÅ Step 3: Classifier makes a prediction\nThe final layer chooses the category with the highest confidence.\n\n---\n\n### üß† Why CNNs work well\n- They reuse the same filter everywhere ‚Üí efficient  \n- They focus on patterns, not pixel positions  \n- They are very good at generalizing  \n\nNow let‚Äôs load our dataset!\n","metadata":{}},{"cell_type":"code","source":"# ============================================================\n# üìò Import all required libraries\n# ============================================================\n\n# TensorFlow is a deep learning framework we will use to build our CNN.\nimport tensorflow as tf\n\n# Layers = building blocks (Conv2D, MaxPooling, Dense)\n# Models = lets us build a neural network easily\nfrom tensorflow.keras import layers, models\n\n# Used to plot graphs and show images\nimport matplotlib.pyplot as plt\n\n# For mathematical operations\nimport numpy as np\n\n# Print TensorFlow version (helpful for debugging)\nprint(\"TensorFlow version:\", tf.__version__)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# üì¶ Loading the CIFAR-10 Dataset\n\nCIFAR-10 is a famous dataset with **60,000 tiny images** (32√ó32 pixels).  \nIt contains 10 categories:\n\n- airplane  \n- car  \n- bird  \n- cat  \n- deer  \n- dog  \n- frog  \n- horse  \n- ship  \n- truck  \n\nLet's load it and normalize the pixel values.\n","metadata":{}},{"cell_type":"code","source":"# ============================================================\n# üì¶ Load the CIFAR-10 dataset from TensorFlow\n# This automatically downloads:\n#   - x_train: training images\n#   - y_train: training labels\n#   - x_test: testing images\n#   - y_test: testing labels\n# ============================================================\n(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n\n# ============================================================\n# üé® Normalize the images\n# Pixel values in images are between 0 and 255.\n# Neural networks learn MUCH better when numbers are small,\n# usually between 0 and 1.\n#\n# Dividing by 255.0 converts every pixel:\n#   e.g., 128 ‚Üí 128/255 ‚âà 0.50\n#   e.g., 255 ‚Üí 1.0\n#\n# This helps the model train faster and more accurately.\n# ============================================================\nx_train = x_train / 255.0\nx_test = x_test / 255.0\n\n# ============================================================\n# üè∑Ô∏è CIFAR-10 Class Names\n# The dataset labels are numbers from 0 to 9.\n# Here we map each number to a human-readable name.\n#\n# Example:\n#   0 ‚Üí airplane\n#   1 ‚Üí car\n#   2 ‚Üí bird\n#   ...\n# ============================================================\nclass_names = [\n    'airplane',\n    'car',\n    'bird',\n    'cat',\n    'deer',\n    'dog',\n    'frog',\n    'horse',\n    'ship',\n    'truck'\n]\n\n# ============================================================\n# üìê Show the shapes of our data\n# x_train.shape ‚Üí (50000, 32, 32, 3)\n#   - 50000 training images\n#   - each image is 32√ó32 pixels\n#   - 3 channels (R, G, B)\n#\n# y_train.shape ‚Üí (50000, 1)\n#   - each image has 1 label (0‚Äì9)\n# ============================================================\nx_train.shape, y_train.shape\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# üëÄ Visualizing Sample Images\n\nBefore training a model, it helps to **see the data**.\n\nYou will notice:\n- images are tiny  \n- categories vary  \n- colors differ  \n\nLet‚Äôs plot 16 random images.\n","metadata":{}},{"cell_type":"code","source":"# ============================================================\n# üëÄ VISUALIZE 16 SAMPLE IMAGES\n# Helps students understand what the model is learning.\n# ============================================================\n\nplt.figure(figsize=(8,8))  # Create a square 8x8 inch figure\n\nfor i in range(16):                # Show 16 images\n    plt.subplot(4, 4, i + 1)       # Create a 4√ó4 grid of images\n    plt.imshow(x_train[i])         # Show image number i\n    label_index = y_train[i][0]    # Get the numeric label (0‚Äì9)\n    plt.title(class_names[label_index])  # Show the class name\n    plt.axis('off')                # Hide axis numbers (looks cleaner)\n\nplt.show()  # Display all images\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# üèóÔ∏è Building a Simple CNN\n\nWe will build a CNN with:\n\n1. **Conv2D Layer**  \n   - Finds edges & textures\n\n2. **MaxPooling**  \n   - Shrinks the image  \n   - Keeps important features\n\n3. **Another Conv2D Layer**  \n   - Learns more complex shapes  \n\n4. **Flatten + Dense**  \n   - Turns image features into a final prediction\n\nThis is a very small CNN, perfect for beginners.\n","metadata":{}},{"cell_type":"code","source":"# ============================================================\n# üèóÔ∏è BUILDING A SIMPLE CNN\n# This CNN has:\n#  - 3 convolutional layers\n#  - 2 pooling layers\n#  - 1 hidden dense layer\n#  - 1 output layer\n# ============================================================\n\nmodel = models.Sequential([\n\n    # --------------------------------------------------------\n    # 1Ô∏è‚É£ FIRST CONVOLUTIONAL LAYER\n    # Conv2D(32 filters, filter size = 3√ó3)\n    # Activation: ReLU (introduces non-linearity)\n    # input_shape = size of each image (32, 32, 3)\n    # --------------------------------------------------------\n    layers.Conv2D(32, (3,3), activation='relu', input_shape=(32,32,3)),\n\n    # --------------------------------------------------------\n    # 2Ô∏è‚É£ FIRST POOLING LAYER\n    # MaxPooling2D(2√ó2) reduces the image size by half\n    # Keeps the strongest features\n    # --------------------------------------------------------\n    layers.MaxPooling2D((2,2)),\n\n    # --------------------------------------------------------\n    # 3Ô∏è‚É£ SECOND CONVOLUTIONAL LAYER\n    # Learns more complex features (64 filters now)\n    # --------------------------------------------------------\n    layers.Conv2D(64, (3,3), activation='relu'),\n\n    # --------------------------------------------------------\n    # 4Ô∏è‚É£ SECOND POOLING LAYER\n    # Again reduces image size\n    # --------------------------------------------------------\n    layers.MaxPooling2D((2,2)),\n\n    # --------------------------------------------------------\n    # 5Ô∏è‚É£ THIRD CONVOLUTIONAL LAYER\n    # Extracts even deeper patterns\n    # --------------------------------------------------------\n    layers.Conv2D(64, (3,3), activation='relu'),\n\n    # --------------------------------------------------------\n    # 6Ô∏è‚É£ FLATTEN LAYER\n    # Converts 3D feature maps into a 1D vector\n    # so it can go into Dense layers\n    # --------------------------------------------------------\n    layers.Flatten(),\n\n    # --------------------------------------------------------\n    # 7Ô∏è‚É£ FULLY CONNECTED LAYER (Dense)\n    # 64 neurons ‚Üí learns final combinations of features\n    # --------------------------------------------------------\n    layers.Dense(64, activation='relu'),\n\n    # --------------------------------------------------------\n    # 8Ô∏è‚É£ OUTPUT LAYER\n    # 10 neurons = 10 classes\n    # softmax ‚Üí probabilities add up to 1\n    # --------------------------------------------------------\n    layers.Dense(10, activation='softmax')\n])\n\n# Show a summary of the model architecture\nmodel.summary()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# üöÄ Training the CNN\n\nWe will train for **10 epochs**.\n\n- `optimizer='adam'` ‚Üí helps the model learn  \n- `loss='sparse_categorical_crossentropy'` ‚Üí for multi-class labels  \n- `metrics=['accuracy']` ‚Üí evaluate performance  \n\nLet's start training!\n","metadata":{}},{"cell_type":"code","source":"# ============================================================\n# ‚öôÔ∏è COMPILE THE MODEL\n# optimizer='adam' ‚Üí adjusts learning rate automatically\n# loss='sparse_categorical_crossentropy' ‚Üí good for integer labels\n# metrics=['accuracy'] ‚Üí measure how well model performs\n# ============================================================\n\nmodel.compile(\n    optimizer='adam',\n    loss='sparse_categorical_crossentropy',\n    metrics=['accuracy']\n)\n\n# ============================================================\n# üöÄ TRAIN THE MODEL\n# history object stores accuracy and loss values\n# epochs=10 ‚Üí the model will see the whole dataset 10 times\n# validation_data ‚Üí test accuracy during training\n# ============================================================\n\nhistory = model.fit(\n    x_train,            # Input images\n    y_train,            # Labels for training images\n    epochs=10,          # Number of passes over the entire dataset\n    validation_data=(x_test, y_test)   # Check performance on test data\n)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# üìä Visualizing Training Progress\n\nThese plots show:\n- How well the model learns  \n- Whether it overfits  \n- Validation vs training accuracy  \n\nLet‚Äôs plot the curves.\n","metadata":{}},{"cell_type":"code","source":"# ============================================================\n# üìä PLOT TRAINING & VALIDATION PERFORMANCE\n# Helps visualize:\n#  - How well the model is learning\n#  - If it is overfitting or underfitting\n# ============================================================\n\nplt.figure(figsize=(12,5))\n\n# ------------------------------------------------------------\n# Accuracy Plot\n# ------------------------------------------------------------\nplt.subplot(1,2,1)\nplt.plot(history.history['accuracy'], label='Train Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.title(\"Model Accuracy\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Accuracy\")\nplt.legend()\n\n# ------------------------------------------------------------\n# Loss Plot\n# ------------------------------------------------------------\nplt.subplot(1,2,2)\nplt.plot(history.history['loss'], label='Train Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.title(\"Model Loss\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.legend()\n\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# üîç Making Predictions\n\nNow the fun part!\n\nWe let the model guess what an image is.  \nWe will:\n\n1. Pick an image  \n2. Show the actual label  \n3. Show the prediction  \n","metadata":{}},{"cell_type":"code","source":"# ============================================================\n# üîç USE MODEL TO MAKE PREDICTIONS\n# model.predict() returns probabilities for each class\n# ============================================================\n\npredictions = model.predict(x_test)\n\n# Function to show an image + prediction\ndef show_prediction(i):\n\n    plt.imshow(x_test[i])   # Show the image\n\n    # Predicted label (highest probability)\n    predicted_label = np.argmax(predictions[i])\n\n    # True label\n    true_label = y_test[i][0]\n\n    plt.title(\n        f\"Prediction: {class_names[predicted_label]}\\n\"\n        f\"Actual: {class_names[true_label]}\"\n    )\n    plt.axis('off')\n\n# Show prediction for image 0\nshow_prediction(0)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}